# I2I_Translation
SATELLITE_GAN :
Recent advancements in deep learning algorithms have enabled the generation of realistic images. Notably, generative adversarial networks (GANs) have demonstrated promising outcomes in the domain of image-to-image translation. Introducing a novel approach, SatelliteGAN, aims to generate maps using satellite images. Leveraging the principles of Pix2Pix and CycleGAN, SatelliteGAN refines both the objective function and the architecture to achieve superior outcomes. By incorporating the perceptual reconstruction loss alongside pixel-level reconstruction loss, SatelliteGAN produces images with vivid colors and reduced blurriness. The perceptual reconstruction loss compels the generator to create samples that share similar feature representations with the ground truth. The model's effectiveness is assessed using the Frechet Inception Distance (FID) and its performance is compared against CycleGAN. Through these evaluations, a determination is made regarding which approach is more adept at generating models under comparable training conditions using the same map dataset.
#Reference: https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/ and
https://arxiv.org/abs/1611.07004
